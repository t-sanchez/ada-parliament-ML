{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Processing  - Transcript to Subject\n",
    "\n",
    "This is not anymore a purely scraping part. This is at the interface between the end of the scraping and the beginning of the formatting of the data in order to use them for the Natural Language Processing. What we do here is reuniting the whole discussion about a *Subject* (same *IdSubject*) into a single field. We lose the person who talked, but we get a much larger corpus of text about a subject that we know to be the same (the algorithm wouldn't guess it !). Note that, at the moment, we only consider the data which are in French (i.e. which have the attribute *LanguageOfText* to *FR*). \n",
    "\n",
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import logging\n",
    "import gensim\n",
    "import bz2\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Processing of the data\n",
    "At first, we load all the *Transcript*s (several files into the *Transcript* folder) and merge it into one large DataFrame. Then, we will process it to merge all the attributes with the same *SubjectId* into one entry. Note that in the resulting DataFrame, there will be a lot of empty entries, as all the indices are not contiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "path = '../datas/scrap/Transcript/'\n",
    "allFiles = glob.glob(os.path.join(path, '*.csv'))\n",
    "\n",
    "# Load and concactenate all the files into one dataset.\n",
    "for file_ in allFiles:\n",
    "    data = pd.read_csv(file_)\n",
    "    dataset += [data]\n",
    "datas = pd.concat(dataset)\n",
    "\n",
    "print(len(data.columns))  \n",
    "#print('Length of the dataset', len(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is also **EXTREMELY LONG TO RUN**. The resulting csv file is the one located at\n",
    "```\n",
    "datas/treated_data/Transcript/FRTextfromsubject.csv\n",
    "```\n",
    "\n",
    "The operation we do is simple. We filter the data by subject and take all the texts which are in French given a subject. Then, we aggregate all the text found into a cell, which maps the *Subject ID* and the *Text* to lists which contains everything we need. Then, we eventually export it to the file cited above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = datas.IdSubject.unique()\n",
    "dict_={'Subject Id':[],'Text':[]}\n",
    "text = ''\n",
    "\n",
    "# Iterate on all the different Subjects (list of IDs)\n",
    "for subject in subjects : \n",
    "    \n",
    "    data_tmp = datas[(datas.IdSubject==subject) & (datas.LanguageOfText == 'FR')]\n",
    "    # Deal with all the NaNs and remove them.\n",
    "    texts = data_tmp[data_tmp.Text == data_tmp.Text]\n",
    "    text = texts.Text.sum()\n",
    "    dict_['Subject Id'] += [subject]\n",
    "    dict_['Text'] += [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the result to a DataFrame, visualise it.\n",
    "transcript = pd.DataFrame(dict_)\n",
    "transcript.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "if not os.path.exists(\"../datas/treated_data/Transcript\"):\n",
    "    os.makedirs(\"../datas/treated_data/Transcript\")\n",
    "transcript.to_csv('../datas/treated_data/Transcript/FRTextfromsubject.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
