{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import logging\n",
    "import gensim\n",
    "import bz2\n",
    "import re\n",
    "from stop_words import get_stop_words\n",
    "from TwitterSearch import *\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../datas/nlp_results/voting_with_topics.csv')\n",
    "df = pd.read_csv('../datas/nlp_results/voting_with_topics_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = [[word for word in re.split(' |\\'|\\n|\\(|\\)|,|;|:|-',\n",
    "                                    document.lower()) if len(word)>1 and (word in words)] \n",
    "             for document in df.text_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demo_vader_instance(text):\n",
    "    \"\"\"\n",
    "    Output polarity scores for a text using Vader approach.\n",
    "\n",
    "    :param text: a text whose polarity has to be evaluated.\n",
    "    \"\"\"\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    vader_analyzer = SentimentIntensityAnalyzer()\n",
    "    #print(vader_analyzer.polarity_scores(text))\n",
    "    return vader_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import treebank\n",
    "pos =[]\n",
    "neg =[]\n",
    "neu =[]\n",
    "compound = []\n",
    "i = 0\n",
    "for text in df.text_eng:\n",
    "    \n",
    "    if i%500 ==0 :\n",
    "        print('{0}%'.format((i*100)/len(df.text_eng)))\n",
    "    i +=1\n",
    "    #email_str = ' '.join(email)\n",
    "    s = demo_vader_instance(text)\n",
    "    polarity = s.polarity_scores(text)\n",
    "    pos += [polarity['pos']]\n",
    "    neg += [polarity['neg']]\n",
    "    neu += [polarity['neu']]\n",
    "    compound += [polarity['compound']]\n",
    "    #pol = 1*(pos>neg) - 1*(neg>pos)\n",
    "    #pol = demo_liu_hu_lexicon(email_str,positive,negative,tokenizer)             \n",
    "    #pola += [pol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['positive']= pos\n",
    "df['negative']= neg\n",
    "df['neutral']= neu\n",
    "df['compound']= compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = df.drop('sentiment',1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('../datas/nlp_results/voting_with_topics_unique_sentiment.csv',index=False)\n",
    "#df.to_csv('../datas/nlp_results/voting_with_topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_tmp = []\n",
    "path = '../datas/scrap/Voting'\n",
    "allFiles = glob.glob(os.path.join(path, 'Session*.csv'))\n",
    "\n",
    "for file_ in allFiles:\n",
    "    print(file_)\n",
    "    data_tmp = pd.read_csv(file_)\n",
    "    dataset_tmp += [data_tmp] \n",
    "data_frame = pd.concat(dataset_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parl = data_frame.ParlGroupCode.unique().tolist()\n",
    "for group in parl :\n",
    "    data_frame.loc[data_frame.ParlGroupCode==group,'ParlGroupCode']= parl.index(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votation_frame = data_frame[['BillTitle','BusinessTitle','FirstName','LastName','Decision','ParlGroupCode']]\n",
    "votation_frame = votation_frame.fillna(value='')\n",
    "votation_frame['text'] = votation_frame['BillTitle']+' '+votation_frame['BusinessTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "votation_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pd.merge(votation_frame,df)).to_csv('../datas/nlp_results/voting_with_topics_sentiment.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
