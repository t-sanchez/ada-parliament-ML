{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import logging\n",
    "import gensim\n",
    "import bz2\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "path = 'datas/Transcript/'\n",
    "#path = 'datas/Vote/'\n",
    "allFiles = glob.glob(os.path.join(path, '*.csv'))\n",
    "dataset = []\n",
    "for file_ in allFiles:\n",
    "    data = pd.read_csv(file_)\n",
    "    dataset += [data]\n",
    "datas = pd.concat(dataset)\n",
    "\n",
    "print(len(data.columns ) )  \n",
    "#print('Length of the dataset', len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = datas.IdSubject.unique()\n",
    "dict_={'Subject Id':[],'Text':[]}\n",
    "text = ''\n",
    "for subject in subjects : \n",
    "    data_tmp = datas[(datas.IdSubject==subject) & (datas.LanguageOfText == 'FR')]\n",
    "    texts = data_tmp[data_tmp.Text == data_tmp.Text]\n",
    "    text = texts.Text.sum()\n",
    "    dict_['Subject Id'] += [subject]\n",
    "    dict_['Text'] += [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transcript = pd.DataFrame(dict_)\n",
    "transcript.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcript.to_csv('datas/Transcript/FRTextfromsubject.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## First of all we load the stop_words list\n",
    "import re\n",
    "\n",
    "## Secondly we remove the common words in our document corpus and tokenize \n",
    "# The re.split function takes as first arguments everything we split at. At the moment, this is \n",
    "# ' ' - '\\' - ''' (apostrophe) -  '\\n' - '(', ')' - ',' - '.' - ':' - ';'\n",
    "# We also filter the words which are shorter than 3 letters, as they are very unlikely to provide any information, \n",
    "# and finally, we remove the common words.\n",
    "texts = [[word for word in re.split(' |\\'|\\n|\\(|\\)|,|;|:|\\.|\\[|\\]|\\â€™',\n",
    "                                    document.lower())] \n",
    "         for document in topics]\n",
    "# Thirdly we remove the words that appear only once in a text - Consider the stemmed version\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "FS = FrenchStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "# Converts a collection of words to its bag of word representation (list of word_id, word_frequency 2-tuples$)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, id2word=dictionary,num_topics=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, bag in enumerate(ldamodel.print_topics(num_words=8,num_topics=2)):\n",
    "    print(\"============\")\n",
    "    print(\"Cluster \", i, \": \", bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
