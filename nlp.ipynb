{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35197\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "path = 'datas/Transcript/'\n",
    "allFiles = glob.glob(os.path.join(path, '*.csv'))\n",
    "\n",
    "for file_ in allFiles:\n",
    "    data = pd.read_csv(file_)\n",
    "    dataset = dataset + list(data[(data['Text'] == data['Text']) & (data['LanguageOfText'] == 'FR')]['Text'].values)\n",
    "    \n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 11.895s.\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "data_samples = dataset\n",
    "\n",
    "with open (\"french_stop_words.txt\", \"r\") as myfile:\n",
    "    stop_words=myfile.read()\n",
    "stop_words = stop_words.split(',')\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words=stop_words)\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 108.913s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "der vs die und in art den das für antrag zu ist imposition al nicht proposition mit von fiscale impôt\n",
      "Topic #1:\n",
      "francs millions cent confédération budget fédéral dépenses montant milliards crédit 000 année augmentation fonds finances projets financement programme commission crédits\n",
      "Topic #2:\n",
      "qu conseil fédéral politique suisse parlement sécurité rapport service armée commission confédération groupe aujourd gestion etat membres débat programme président\n",
      "Topic #3:\n",
      "conseil fédéral motion commission loi projet fédérale rapport national confédération cantons postulat mesures propose parlement matière cadre également révision vigueur\n",
      "Topic #4:\n",
      "qu loi cantons personnes système santé nombre domaine manière situation aujourd agit certain exemple simplement solution problèmes jeunes ailleurs certains\n",
      "Topic #5:\n",
      "suisse européenne union qu politique formation marché entreprises recherche développement économique économie suisses accords écoles produits libre domaine matière prix\n",
      "Topic #6:\n",
      "suisse droits convention tribunal procédure personnes code matière etats protection asile pénal qu recours etat fédéral pénale autorités international justice\n",
      "Topic #7:\n",
      "initiative qu commission projet cantons loi parlementaire populaire majorité constitution peuple aujourd canton matière fédérale animaux protection énergie parlement initiatives\n",
      "Topic #8:\n",
      "assurance qu cent système prestations taux maladie personnes avs primes coûts assurances sociale assurés caisses révision prévoyance situation cantons revenu\n",
      "Topic #9:\n",
      "commission conseil proposition minorité article majorité qu alinéa fédéral loi etats voix projet propose groupe décision national propositions version suivre\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open (\"stop_words.txt\", \"r\") as myfile:\n",
    "    stop_words=myfile.read()\n",
    "#stop_words = stop_words.replace('\\t')    \n",
    "stop_words = stop_words.split('\\n')\n",
    "#for i in range(len(stop_words))\n",
    "k = []\n",
    "for i in range(len(stop_words)) :\n",
    "    k.append(stop_words[i].split('\\t')[0])\n",
    "\n",
    "k\n",
    "str_ = ''\n",
    "for i in range(len(k)) :\n",
    "    str_ += k[i]+','\n",
    "with open(\"French_stop_words.txt\", \"w\") as text_file:\n",
    "    text_file.write(str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je,de,est,pas,le,vous,la,tu,que,un,il,et,à,a,ne,les,ce,en,on,ça,une,ai,pour,des,moi,qui,nous,y,mais,me,dans,du,bien,elle,si,tout,plus,non,mon,suis,te,au,avec,va,oui,toi,fait,ils,as,être,faire,se,comme,était,sur,quoi,ici,sais,lui,veux,ma,là,rien,dit,es,où,votre,pourquoi,sont,cette,quand,par,son,ton,peux,vais,dire,alors,comment,avez,bon,ou,très,merci,ont,même,jamais,aussi,voir,chose,allez,tous,deux,ces,faut,sa,êtes,été,ta,fais,avoir,peut,autre,m,encore,maintenant,peu,mes,vraiment,temps,notre,toujours,vie,sans,juste,oh,avait,accord,vu,monde,quelque,fois,aller,trop,viens,crois,dieu,dois,homme,père,sûr,aux,leur,avant,étais,besoin,femme,aime,personne,avais,chez,vrai,ans,mal,ses,parler,vos,après,mort,veut,eu,sera,bonne,parce,mieux,petit,voilà,tes,ca,dis,beaucoup,depuis,doit,vois,mère,vas,monsieur,quel,déjà,fille,gens,donc,jour,soir,autres,ii,toute,bonjour,ll,maison,nom,argent,nos,ouais,pense,merde,nuit,papa,cela,salut,cet,avons,reste,désolé,maman,peur,arrive,seul,vite,prendre,regarde,air,soit,trois,quelle,passé,savoir,plaît,choses,moins,fils,entre,bas,appelle,passe,ah,tête,demain,grand,arrête,faites,voulez,hé,attends,hein,enfants,assez,raison,aurais,voulais,elles,parle,ok,jours,dû,moment,heure,puis,gars,hommes,amour,tard,toutes,sommes,tuer,eh,ami,connais,petite,aider,chance,savez,partir,sait,combien,voiture,tant,pris,part,problème,prends,porte,coup,serait,venir,hui,famille,travail,pu,seule,sens,ni,allons,revoir,idée,putain,passer,contre,comprends,entendu,trouvé,trouver,vieux,vient,pendant,aurait,quelques,attention,demande,chercher,sous,voici,pourrait,sang,pouvez,sortir,question,histoire,amis,venez,frère,rester,fini,ville,nouveau,truc,tiens,mois,eux,mec,yeux,laisse,super,belle,longtemps,police,eau,heures,car,importe,cas,vont,chaque,terre,place,tué,type,main,pardon,ensemble,seulement,guerre,beau,vers,mme,prie,devant,trouve,partie,suite,compris,matin,leurs,aucun,arrivé,dessus,chérie,mettre,aide,étaient,ie,perdu,fin,sois,premier,genre,aimerais,droit,donne,attendez,jeune,feu,devrais,enfant,chambre,gros,côté,venu,loin,laisser,donner,jouer,savais,compte,s,parlé,minutes,regardez,train,première,pouvoir,aura,mourir,dernière,donné,ia,mari,écoute,enfin,devrait,mis,film,aucune,fort,façon,pays,prêt,madame,femmes,affaire,pourrais,espère,parti,h,boulot,endroit,fou,corps,hier,dont,désolée,grande,point,cinq,dehors,filles,cause,vivre,près,pensais,garçon,chef,haut,capitaine,dirait,bébé,celui,demandé,possible,mains,ainsi,quatre,nouvelle,années,plein,semaine,dites,croire,marche,tour,école,manger,plutôt,docteur,ceux,vérité,vue,arrêter,essaie,envie,bientôt,instant,dernier,affaires,arriver,demander,meilleur,font,derrière,c,dollars,presque,dr,tellement,tomber,journée,voulait,appeler,bureau,confiance,garde,attendre,numéro,serai,dur,á,souviens,o,voyez,cours,bonsoir,route,fera,prend,cul,abord,important,peine,croyais,mot,devez,suffit,minute,ferme,ben,plaisir,chien,jeu,seigneur,messieurs,'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (\"stop_words.txt\", \"r\") as myfile:\n",
    "    stop_words=myfile.read()\n",
    "stop_words = stop_words.split('\\n')\n",
    "k = ''\n",
    "for i in range(len(stop_words)) :\n",
    "    k+= stop_words[i].split('\\t')[1]+','\n",
    "k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open (\"french_stop_words.txt\", \"w\") as myfile:\n",
    "    myfile.write(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
