# 02 - Natural Language Processing (NLP)

In this step, we train our NLP model on the *Transcript* data, and try to find as accurately as possible the topics that are treated in the parliament (we will need to determine by hand, from the bag of words, whether every topic make sense). We also need to vary the number of topics from one test to another, to find the optimal number of topics that we would need to get a meaningful result for each of the objects that are voted. There are two files here `01-nlp_Gensim` and `02-MLOnVotation`.

## 01 - NLP with Gensim
This file performs what we have described above, using to achieve it the [Gensim](https://radimrehurek.com/gensim/) library. We perform several preprocessing of the data in order to achieve accurate results. Some necessary steps are to exclude the most common words, which would not help determining the subject which is discussed. This includes the vocabulary specific to the parliament that brings nothing, like *Conseil fédéral*, ... This is some kind of iterative process, where we remove the meaningless words from the bag of words we obtain after having applied the algorithm. The results, as we just said, is a bag of words which describes a subject according to the algorithm (i.e. those words appear often together).

Note that at the moment, the NLP is only done with the French texts. We will not do the analysis of the texts which are in German, as then combining the results of the topics we get for each of the languages would become extremely cumbersome. NLP in French on its own allows already to get a good grasp at what topics are discussed. Moreover, due to some shifts in the projects goal further on, NLP is not as fundamental as it previously was, and hence doing the analysis of the texts in German/Italian is really not useful at all anymore.

## 02 - Machine Learning on the Votations
We now take the big step of applying the model we created in `01-nlp_Gensim.ipynb` to actual new data : the *BusinessTitle* and *BillTitle* attributes of the *Vote* field. We want to see how accurately our model is able to classify what the law which is being voted at the Parliament is close to the different topics it found. We will have as a result a percentage of chance of belonging to each of the clusters. The result, shown in the `../datas/nlp_results/voting_with_topics.csv` file, shows that actually even with the first training of our model on a few topics, the classification is quite accurate, up to some problems maybe due to a lack of different topics (it seems that no topic is dedicated to education in our very first model).
